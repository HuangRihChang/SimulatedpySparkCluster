{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PySpark**: The Apache Spark Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook shows how to connect Jupyter notebooks to a Spark cluster to process data using Spark Python API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster overview\n",
    "\n",
    "| Application     | URL                                      | Description                                                |\n",
    "| --------------- | ---------------------------------------- | ---------------------------------------------------------- |\n",
    "| JupyterLab      | [localhost:8888](http://localhost:8888/) | Cluster interface with built-in Jupyter notebooks          |\n",
    "| Spark Driver    | [localhost:4040](http://localhost:4040/) | Spark Driver web ui                                        |\n",
    "| Spark Master    | [localhost:8080](http://localhost:8080/) | Spark Master node                                          |\n",
    "| Spark Worker I  | [localhost:8081](http://localhost:8081/) | Spark Worker node with 1 core and 512m of memory (default) |\n",
    "| Spark Worker II | [localhost:8082](http://localhost:8082/) | Spark Worker node with 1 core and 512m of memory (default) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Spark Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Connection\n",
    "\n",
    "To connect to the Spark cluster, create a SparkSession object with the following params:\n",
    "\n",
    "+ **appName:** application name displayed at the [Spark Master Web UI](http://localhost:8080/);\n",
    "+ **master:** Spark Master URL, same used by Spark Workers;\n",
    "+ **spark.executor.memory:** must be less than or equals to docker compose SPARK_WORKER_MEMORY config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx matplotlib graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/19 19:54:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/19 20:22:47 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "22/11/19 20:22:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:716)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:152)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:258)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:168)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:203)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark test demo\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More confs for SparkSession object in standalone mode can be added using the **config** method. Checkout the API docs [here](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SparkSession)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Introduction\n",
    "\n",
    "We will be using Spark Python API to read, process and write data. Checkout the API docs [here](https://spark.apache.org/docs/latest/api/python/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Read\n",
    "\n",
    "Let's read some UK's macroeconomic data ([source](https://www.kaggle.com/bank-of-england/a-millennium-of-macroeconomic-data)) from the cluster's simulated **Hadoop distributed file system (HDFS)** into a Spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(path=\"data/uk-macroeconomic-data.csv\", sep=\",\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then display some dataframe metadata, such as the number of rows and cols and its schema (cols name and type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/19 19:36:14 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Real GDP of England at market prices: string (nullable = true)\n",
      " |-- Real GDP of England at factor cost : string (nullable = true)\n",
      " |-- Real UK GDP at market prices, geographically-consistent estimate based on post-1922 borders: string (nullable = true)\n",
      " |-- Real UK GDP at factor cost, geographically-consistent estimate based on post-1922 borders: string (nullable = true)\n",
      " |-- Index of real UK GDP at factor cost - based on changing political boundaries, : string (nullable = true)\n",
      " |-- Composite estimate of English and (geographically-consistent) UK real GDP at factor cost: string (nullable = true)\n",
      " |-- HP-filter of log of real composite estimate of English and UK real GDP at factor cost: string (nullable = true)\n",
      " |-- Real UK gross disposable national income at market prices, constant border estimate: string (nullable = true)\n",
      " |-- Real consumption: string (nullable = true)\n",
      " |-- Real investment: string (nullable = true)\n",
      " |-- Stockbuilding contribution: string (nullable = true)\n",
      " |-- Real government consumption of goods and services: string (nullable = true)\n",
      " |-- Export volumes: string (nullable = true)\n",
      " |-- Import volumes: string (nullable = true)\n",
      " |-- Nominal GDP of England at market prices: string (nullable = true)\n",
      " |-- Nominal UK GDP at market prices: string (nullable = true)\n",
      " |-- Nominal UK GDP at market prices.1: string (nullable = true)\n",
      " |-- Population (GB+NI): string (nullable = true)\n",
      " |-- Population (England): string (nullable = true)\n",
      " |-- Employment: string (nullable = true)\n",
      " |-- Unemployment rate: string (nullable = true)\n",
      " |-- Average weekly hours worked: string (nullable = true)\n",
      " |-- Capital Services, whole economy: string (nullable = true)\n",
      " |-- TFP growth: string (nullable = true)\n",
      " |-- Labour productivity: string (nullable = true)\n",
      " |-- Labour productivity.1: string (nullable = true)\n",
      " |-- Labour share, whole economy excluding rents: string (nullable = true)\n",
      " |-- GDP deflator at market prices: string (nullable = true)\n",
      " |-- Export prices: string (nullable = true)\n",
      " |-- Import prices: string (nullable = true)\n",
      " |-- Terms of Trade: string (nullable = true)\n",
      " |-- $ Oil prices: string (nullable = true)\n",
      " |-- Earnings per head: string (nullable = true)\n",
      " |-- Consumer price index: string (nullable = true)\n",
      " |-- Consumer price inflation: string (nullable = true)\n",
      " |-- Real consumption wages: string (nullable = true)\n",
      " |-- Wholesale/producer price index: string (nullable = true)\n",
      " |-- Bank Rate: string (nullable = true)\n",
      " |-- Bank Rate.1: string (nullable = true)\n",
      " |-- 10 year/medium-term government bond yields: string (nullable = true)\n",
      " |-- Consols / long-term government bond yields: string (nullable = true)\n",
      " |-- Mortgage rates: string (nullable = true)\n",
      " |-- Corporate borrowing rate from banks: string (nullable = true)\n",
      " |-- Corporate bond yields: string (nullable = true)\n",
      " |-- Share prices: string (nullable = true)\n",
      " |-- $/£ exchange rate: string (nullable = true)\n",
      " |-- Real $/£ exchange rate: string (nullable = true)\n",
      " |-- Nominal ERI: string (nullable = true)\n",
      " |-- Real ERI: string (nullable = true)\n",
      " |-- House price index: string (nullable = true)\n",
      " |-- Credit : string (nullable = true)\n",
      " |-- Secured credit: string (nullable = true)\n",
      " |-- Bank of England Balance sheet: string (nullable = true)\n",
      " |-- Bank of England Balance sheet.1: string (nullable = true)\n",
      " |-- Coin in circulation outside the Bank of England: string (nullable = true)\n",
      " |-- Notes and coin in circulation: string (nullable = true)\n",
      " |-- Monetary base: string (nullable = true)\n",
      " |-- M1: string (nullable = true)\n",
      " |-- Broad Money : string (nullable = true)\n",
      " |-- Public sector Total Managed Expenditure: string (nullable = true)\n",
      " |-- Public sector Total Managed Expenditure.1: string (nullable = true)\n",
      " |-- Public Sector Total Receipts: string (nullable = true)\n",
      " |-- Public Sector Total Receipts.1: string (nullable = true)\n",
      " |-- Public Sector Net Lending(+)/Borrowing(-): string (nullable = true)\n",
      " |-- Public Sector Net Lending(+)/Borrowing(-).1: string (nullable = true)\n",
      " |-- UK Public sector debt: string (nullable = true)\n",
      " |-- UK Public sector debt.1: string (nullable = true)\n",
      " |-- UK Public sector debt.2: string (nullable = true)\n",
      " |-- Central Government Gross Debt: string (nullable = true)\n",
      " |-- Central Government Gross Debt.1: string (nullable = true)\n",
      " |-- Trade deficit: string (nullable = true)\n",
      " |-- Trade deficit.1: string (nullable = true)\n",
      " |-- Current account : string (nullable = true)\n",
      " |-- Current account .1: string (nullable = true)\n",
      " |-- Current account deficit including estimated non-monetary bullion flows: string (nullable = true)\n",
      " |-- Current account deficit including estimated non-monetary bullion flows.1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will get UK's population and unemployment rate thoughtout the years. Let's start by selecting the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = data.select([\"Description\", \"Population (GB+NI)\", \"Unemployment rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------------+\n",
      "|Description|Population (GB+NI)|Unemployment rate|\n",
      "+-----------+------------------+-----------------+\n",
      "|      Units|              000s|                %|\n",
      "|       1209|              null|             null|\n",
      "|       1210|              null|             null|\n",
      "|       1211|              null|             null|\n",
      "|       1212|              null|             null|\n",
      "|       1213|              null|             null|\n",
      "|       1214|              null|             null|\n",
      "|       1215|              null|             null|\n",
      "|       1216|              null|             null|\n",
      "|       1217|              null|             null|\n",
      "+-----------+------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unemployment.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully selected the desired columns but two problems were found:\n",
    "+ The first line contains no data but the unit of measurement of each column;\n",
    "+ There are many years with missing population and unemployment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then remove the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_description = unemployment.filter(unemployment['Description'] == 'Units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------------+\n",
      "|Description|Population (GB+NI)|Unemployment rate|\n",
      "+-----------+------------------+-----------------+\n",
      "|      Units|              000s|                %|\n",
      "+-----------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cols_description.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = unemployment.join(other=cols_description, on=['Description'], how='left_anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------------+\n",
      "|Description|Population (GB+NI)|Unemployment rate|\n",
      "+-----------+------------------+-----------------+\n",
      "|       1209|              null|             null|\n",
      "|       1210|              null|             null|\n",
      "|       1211|              null|             null|\n",
      "|       1212|              null|             null|\n",
      "|       1213|              null|             null|\n",
      "|       1214|              null|             null|\n",
      "|       1215|              null|             null|\n",
      "|       1216|              null|             null|\n",
      "|       1217|              null|             null|\n",
      "|       1218|              null|             null|\n",
      "+-----------+------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unemployment.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now, let's drop the dataframe rows with missing data and refactor its columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = unemployment.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = unemployment.\\\n",
    "               withColumnRenamed(\"Description\", 'year').\\\n",
    "               withColumnRenamed(\"Population (GB+NI)\", \"population\").\\\n",
    "               withColumnRenamed(\"Unemployment rate\", \"unemployment_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------------+\n",
      "|year|population|unemployment_rate|\n",
      "+----+----------+-----------------+\n",
      "|1855|     23241|             3.73|\n",
      "|1856|     23466|             3.52|\n",
      "|1857|     23689|             3.95|\n",
      "|1858|     23914|             5.23|\n",
      "|1859|     24138|             3.27|\n",
      "|1860|     24360|             2.94|\n",
      "|1861|     24585|             3.72|\n",
      "|1862|     24862|             4.68|\n",
      "|1863|     25142|             4.15|\n",
      "|1864|     25425|             2.99|\n",
      "+----+----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unemployment.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we persist the unemployment data into the cluster's simulated **HDFS**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.repartition(1).write.csv(path=\"hdfs://uk-macroeconomic-unemployment-data.csv\", sep=\",\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Do some fun to compare spark and python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark: 0.00017762184143066406\n",
      "python generator: 9.838774681091309\n",
      "python loops: 7.480478525161743\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from time import time\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "big_list = range(100000000)\n",
    "\n",
    "rdd5 = sc.parallelize(big_list,5)\n",
    "\n",
    "start = time()\n",
    "sparkodds = rdd5.filter(lambda x: x % 2 != 0)\n",
    "print(\"spark:\", time() - start)\n",
    "\n",
    "start = time()\n",
    "gen_odds = list(filter(lambda x: x % 2 != 0, big_list))\n",
    "print(\"python generator:\", time() - start)\n",
    "\n",
    "start = time()\n",
    "pyodds = [x for x in big_list if  x % 2 != 0]\n",
    "print(\"python loops:\", time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 0.0007357597351074219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark: 1.139918565750122\n"
     ]
    }
   ],
   "source": [
    "text_path = '/usr/share/doc/python3/copyright'\n",
    "\n",
    "start = time()\n",
    "with open(text_path, \"r\") as f:\n",
    "    n_lines, n_python_lines = [],[]\n",
    "    for line in f:\n",
    "        if 'python' in line.lower():\n",
    "            n_python_lines.append(line)\n",
    "        n_lines.append(line)\n",
    "    with open('py_results.txt', 'w') as file_obj:\n",
    "        file_obj.write(f'Number of lines: {len(n_lines)}\\n')\n",
    "        file_obj.write(f'Number of lines with python: {len(n_python_lines)}\\n')\n",
    "print(\"python:\", time() - start)\n",
    "\n",
    "\n",
    "spark_txt = sc.textFile(\"file:///\"+text_path, minPartitions=5)\n",
    "start = time()\n",
    "python_lines = spark_txt.filter(lambda line: 'python' in line.lower())\n",
    "with open('results.txt', 'w') as file_obj:\n",
    "    file_obj.write(f'Number of lines: {spark_txt.count()}\\n')\n",
    "    file_obj.write(f'Number of lines with python: {python_lines.count()}\\n')\n",
    "print(\"spark:\", time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 319\n",
      "Number of lines with python: 52\n"
     ]
    }
   ],
   "source": [
    "!cat results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 319\n",
      "Number of lines with python: 52\n"
     ]
    }
   ],
   "source": [
    "!cat py_results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
